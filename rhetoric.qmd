---
title: "Rhetorical Analysis of 'Consequences of Asking Sensitive Questions in Surveys'"
author: Kyle O'Connor
date: 02/10/2026
format: 
  html:
    link-citations: true
  pdf:
    link-citations: true
bibliography: references.bib
---
---

  Yan's first claim is that a person's view of sensitivity is primarily dependent on their personal beliefs in addition to the structure of the survey question. One of the ways Yan supports this claim is through an ethos lens. In the paper it states, "Andreenkova & Javeline (2019) show empirically that questions on income and ownership of items indicating household finance, risk behaviors (such as binge drinking and smoking), and health were perceived to be similarly sensitive across the ten countries they examined. By contrast, questions on political behavior and views, family structure, knowledge, and values appeared to be extremely sensitive in some countries but less so in others" [@yanConsequencesAskingSensitive2020]. Yan is relying on the expertise of Andreenkova and Javeline as a means of supporting this claim, as this is being quoted from the original source. I think that this argument would be stronger if Yan had explicitly mentioned what the credentials of Andreenkova and Javeline are in relation to this topic, as nothing is mentioned within the paper itself. While it can be correctly assumed that they have worked in this field and hold some expert-level knowledge of this topic, even readers who are already knowledgeable in this field may not know who these people are. As a result, it slightly diminishes the strength of the entire argument. 

  Yan's second claim is that certain types of questions lead to a higher rate of non-response. To support this claim, Yan primarily relies on logos through the use of statistics. In relation to this claim, Yan writes, "[It was] found that the return rate of mail surveys decreases as the topic becomes more sensitive; the return rate was 41% when the mail survey was announced to be about leisure activities, 33% for a work related survey, 22% for a survey on sex, and 18% when the survey was about money"  [@yanConsequencesAskingSensitive2020]. Yan is providing these statistics in a way that clearly shows the relationship between sensitivity and response rate. Overall, I think this is a very effective argument because Yan goes into detail about the nature and credibility of this study before diving into the results, which lends additional ethical status to this claim.

  Yan's third claim is that non-response and misreporting error types are not independent types of error. To show this relationship, Yan again relies on logos and ethos lenses to support this claim. Yan writes, "Even though the overall measurement bias is slightly larger than non-response bias, Tourangeau et al. (2010) found that nonvoters over-reported significantly more than voters; over-reporting for the 2004 election is 1.5% for voters and 53.1% for nonvoters, whereas over-reporting for the 2006 election is 1.6% for voters and 46.5% for nonvoters" [@yanConsequencesAskingSensitive2020]. Similar to Yan's first claim, no specific mention of Tourangeau's credentials is mentioned in the actual text of the paper. While again it can be correctly assumed that he is a very credible source when it comes to discussing survey methodology, as he has worked at Gallup and as a professor at the University of Michigan, I think Yan's argument would be enhanced through an explicit mention of Tourangeau's credentials. Unlike Yan's first argument however, this claim is also supported through the use of charts, data, and statistics. The details of the study that lead to the findings was clearly defined, which makes the findings come off as more trustworthy and replicable. Overall, I think Yan's third claim is sufficiently supported through the logos lens, but less so with the ethos lens.
